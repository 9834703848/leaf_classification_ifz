{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs available, TensorFlow is using only CPU.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Disable all GPUs by setting the environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable all GPUs\n",
    "\n",
    "# Alternatively, using TensorFlow to set visible devices to an empty list for 'GPU'\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Verify that TensorFlow is not using any GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs are still available:\", gpus)\n",
    "else:\n",
    "    print(\"No GPUs available, TensorFlow is using only CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from datetime import datetime\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import json\n",
    "from tensorflow import keras\n",
    "from leaf_utils import *\n",
    "from leaf_form_processing import *\n",
    "from leaf_parameter_calculate import *\n",
    "from circle_parameter_calculate import *\n",
    "from circle_processing import *\n",
    "from leaf_predition import *\n",
    "from imaging_circle_updated import *\n",
    "from imaging_leaf_updated import *\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn.config import Config\n",
    "from single_slope_calculation import *\n",
    "from single_area_prediction import *\n",
    "from pathlib import Path\n",
    "\n",
    "# Define matrices F1 and F4\n",
    "F1 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "F4 = np.array([\n",
    "    [1, 1, 1, 1, -4, 1, 1, 1, 1],\n",
    "    [1, 1, -3.6, -3.2, -3, -3.2, -3.6, 1, 1],\n",
    "    [1, -3.6, -2.8, -2.2, -2, -2.2, -2.8, -3.6, 1],\n",
    "    [1, -3.2, -2.2, -1.4, -1, -1.4, -2.2, -3.2, 1],\n",
    "    [-4, -3, -2, -1, 0, -1, -2, -3, -4],\n",
    "    [1, -3.2, -2.2, -1.4, -1, -1.4, -2.2, -3.2, 1],\n",
    "    [1, -3.6, -2.8, -2.2, -2, -2.2, -2.8, -3.6, 1],\n",
    "    [1, 1, -3.6, -3.2, -3, -3.2, -3.6, 1, 1],\n",
    "    [1, 1, 1, 1, -4, 1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Define necessary paths and constants \\\\192.168.91.83\\Register\\farmerspace\\fs24_zkr_tellow_frauenhofer\\proc\\orthomosaic\\rededge-p\\9m\\20240801.tif\n",
    "ORTHO_FOLDER = \"//192.168.91.83/Register/farmerspace/fs24_zkr_tellow_frauenhofer/proc/orthomosaic/rededge-p/9m/\"\n",
    "ortho_file = \"20240819.tif\"\n",
    "DEM_FOLDER = \"C:/temp_disease_quantification/fs24_zkr_tellow_frauenhofer/proc/dem/rededge-p/9m/\"\n",
    "SLOPE_FOLDER= \"C:/temp_disease_quantification/fs24_zkr_tellow_frauenhofer/proc/a2c/rededge-p/9m\"\n",
    "AREA_FOLDER= \"C:/temp_disease_quantification/fs24_zkr_tellow_frauenhofer/proc/area_coeficient/rededge-p/9m\"\n",
    "shape_plot_path=\"//192.168.91.83/Register/farmerspace/fs24_zkr_tellow_frauenhofer/raw/gis/PrecisionBeet_fieldtrial_aktuell/PrecisionBeet_fieldtrial\"\n",
    "shape_plot_file = \"shape_mini_wgs_automatic_scoring.gpkg\"\n",
    "RESULTS_FOLDER_ROOT = \"results\"\n",
    "design_miniplot_path =\"qgis_labels.xlsx\"\n",
    "\n",
    "pipeline_sources_path = \"//192.168.91.193/Dokumente/ifz_daten/COBRI/SOURCES/R/pipeline_sources\"\n",
    "path_model=\"//192.168.91.193/Dokumente/ifz_daten/COBRI/co19_cobri/proc/ml_modeling/classifiers/\"\n",
    "INSTANCE_FOLDER=\"C:/temp_disease_quantification/fs24_zkr_tellow_frauenhofer/proc/leaf_shape/rededge-p/9m\"\n",
    "rdata_file = \"Multispectral_indices.csv\"\n",
    "pipeline_path = \"result_dict.json\"\n",
    "MRCNN_ROOT = \"C:/Users/barreto/OneDrive - Institut f端r Zuckerr端benforschung/project_mask_rcnn/leaf_seg_SHRINATH/shrinath/Envs/models\"\n",
    "# MRCNN_MODEL_DIR = \"C:/Users/barreto/AppData/Local/anaconda3/envs/abc/Lib/site-packages/mrcnn/models/selected_weights/05_100plus0\"\n",
    "MRCNN_MODEL_NAME = \"mask_rcnn_sugarbeat_0050.h5\"\n",
    "MRCNN_MODEL_PATH = \"C:/Users/barreto/OneDrive - Institut f端r Zuckerr端benforschung/project_mask_rcnn/leaf_seg_SHRINATH/shrinath/Envs/models/selected_weights/05_100plus0/mask_rcnn_sugarbeat_0050.h5\"\n",
    "# MRCNN_MODEL_PATH = os.path.join(MODEL_DIR, MRCNN_MODEL_NAME)\n",
    "date_id = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "\n",
    "# Load the design miniplot\n",
    "design_miniplot = pd.read_excel(design_miniplot_path, sheet_name=\"data\")\n",
    "\n",
    "# Load model pipeline configuration\n",
    "model_label = \"wf_022\"\n",
    "with open(pipeline_path, 'r') as f:\n",
    "    pipeline = json.load(f)\n",
    "coef_names = pipeline['coef']\n",
    "class_output = pipeline[\"class_character\"]\n",
    "\n",
    "# Set constants and parameters\n",
    "UTMzone = 32\n",
    "input_image_size = 2400  # Size of images that cut from the big orthomosaic to predict the leaves \n",
    "rad = 0.05               # Radius for circle instance\n",
    "n_ins = 100              # Number of instances\n",
    "n_ins_test = n_ins * 1.5 # Instances for sampling (LEAF form)\n",
    "th_prediction = 20       # Minimal percentage of vegetation to sample\n",
    "min_pix_pred = 30        # Minimal number of pixels of vegetation to sample\n",
    "th_erosion = 10          # Erosion activation threshold\n",
    "IMAGING = True           # Option to print images\n",
    "PRINT_SHAPE_SEL_LEAF = True\n",
    "FOLDER_DEM_FEATURES = DEM_FOLDER\n",
    "MAX_AREA_LEAF = 225      # Maximum leaf area in cm2\n",
    "VERSION_PARAMETERS = \"0001\"\n",
    "\n",
    "# Check necessary files\n",
    "def check_files_exist(paths):\n",
    "    \"\"\"Check if all the files in the list exist.\"\"\"\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"{path} does not exist, PLEASE CHECK FILES/PATHS\")\n",
    "    print(\"All crucial files checked\")\n",
    "\n",
    "# Define file paths\n",
    "\n",
    "id_file = ortho_file[:8]\n",
    "INSTANCE_FORM = \"BOTH\"\n",
    "DI_THRESHOLD = 0.50  \n",
    "bands = [\"BLUE\", \"GREEN\", \"RED\", \"REDEDGE\",\"NIR\"]\n",
    "file_id_ortho = ortho_file[:8]\n",
    "ortho_file_path = os.path.join(ORTHO_FOLDER, ortho_file)\n",
    "dem_file_path = os.path.join(DEM_FOLDER, ortho_file)\n",
    "shape_plot_full_path = 'shape_mini_wgs_automatic_scoring.gpkg' #os.path.join(shape_plot_path, shape_plot_file)\n",
    "cnn_model_path = os.path.join(pipeline['model_path'][0], pipeline['model_list'][0])\n",
    "\n",
    "# Check if necessary files exist\n",
    "check_files_exist([ortho_file_path, dem_file_path, cnn_model_path])\n",
    "\n",
    "# Create results folder if it doesn't exist\n",
    "RESULTS_FOLDER_ROOT = os.path.join(RESULTS_FOLDER_ROOT, date_id)\n",
    "os.makedirs(RESULTS_FOLDER_ROOT, exist_ok=True)\n",
    "print(f\"Results folder created at: {RESULTS_FOLDER_ROOT}\")\n",
    "\n",
    "# Define additional paths\n",
    "a2c_path_list = [os.path.join(DEM_FOLDER, \"a2c\", ortho_file)]\n",
    "area_coeficient_path_list = [os.path.join(DEM_FOLDER, \"area_coeficient\", ortho_file)]\n",
    "\n",
    "# LEAF PROCESSING\n",
    "INSTANCE_FORM = \"LEAF\"  # Set to \"LEAF\" or \"BOTH\"\n",
    "shape_leaf_path = os.path.join(INSTANCE_FOLDER, f\"{file_id_ortho}.gpkg\")\n",
    "\n",
    "# Load the .RData file\n",
    "Index_List = pd.read_csv(rdata_file)\n",
    "\n",
    "# Initialize variables\n",
    "values = None\n",
    "file = 1\n",
    "\n",
    "# PROCESSING\n",
    "\n",
    "# Load sample ortho DEM\n",
    "print(f\"Loading ortho file: {ortho_file_path}\")\n",
    "M1 = rasterio.open(ortho_file_path)\n",
    "\n",
    "# Load features\n",
    "slope_path = os.path.join(SLOPE_FOLDER, ortho_file)\n",
    "if not os.path.exists(slope_path):\n",
    "    single_slope_calculation(DEM_FOLDER, ortho_file, slope_path, epsg_utm=\"EPSG:32632\", epsg_wgs84=\"EPSG:4326\", chunk_size=1000)\n",
    "if not os.path.exists(slope_path):\n",
    "    print(\"Slope file missing. Please calculate slope!\")\n",
    "\n",
    "area_path = os.path.join(AREA_FOLDER, ortho_file)\n",
    "if not os.path.exists(area_path):\n",
    "    single_area_prediction(DEM_FOLDER, ortho_file, area_path)\n",
    "if not os.path.exists(area_path):\n",
    "    print(\"Area coefficient file missing. Please calculate area coefficient!\")\n",
    "\n",
    "with rasterio.open(ortho_file_path) as src:\n",
    "    profile = src.profile\n",
    "\n",
    "# Extract data from the ortho and DEM files\n",
    "rmu_data_t = np.mean(real_res(ortho_file_path, UTMzone))\n",
    "rmux_data_t = real_res(ortho_file_path, UTMzone)[0]\n",
    "rmuy_data_t = real_res(ortho_file_path, UTMzone)[1]\n",
    "D1 = rasterio.open(dem_file_path)\n",
    "rde_data_t = np.mean(real_res(dem_file_path, UTMzone))\n",
    "\n",
    "# Load pixel size and slope\n",
    "pix_size = rasterio.open(area_path)\n",
    "a2cam = rasterio.open(slope_path)\n",
    "\n",
    "# Load leaf shape\n",
    "shape_plot = gpd.read_file(\"shape_automatic_scoring.gpkg\")\n",
    "shape_plot = shape_plot.to_crs('EPSG:4326')\n",
    "shape_plot['geometry'] = shape_plot['geometry'].apply(convert_multipolygon_to_polygon)\n",
    "\n",
    "if 'plot_id' not in shape_plot.columns:\n",
    "    shape_plot['plot_id'] = range(1, len(shape_plot) + 1)\n",
    "plot_list_id = sorted(shape_plot['plot_id'])    \n",
    "# Check and process LEAF instances\n",
    "LEAF_PROCESSING = False\n",
    "if INSTANCE_FORM in [\"LEAF\", \"BOTH\"]:\n",
    "    if os.path.exists(shape_leaf_path):\n",
    "        # Read the shapefile if it exists\n",
    "        shape_leaf = gpd.read_file(shape_leaf_path)\n",
    "        print(\"Shapefile read successfully.\")\n",
    "        LEAF_PROCESSING = True\n",
    "    else:\n",
    "        print('Loading the Mask R-CNN Model...')\n",
    "\n",
    "        # Define configuration for Mask R-CNN\n",
    "        class CocoSynthConfig(Config):\n",
    "            NAME = \"cocosynth_dataset\"\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "            NUM_CLASSES = 1 + 1  # Background + 1 leaf type\n",
    "            IMAGE_MIN_DIM = 2048\n",
    "            IMAGE_MAX_DIM = 2048\n",
    "            STEPS_PER_EPOCH = 2000\n",
    "            VALIDATION_STEPS = 100\n",
    "            BACKBONE = 'resnet101'\n",
    "            RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "            TRAIN_ROIS_PER_IMAGE = 32\n",
    "            MAX_GT_INSTANCES = 50\n",
    "            POST_NMS_ROIS_TRAINING = 500\n",
    "            \n",
    "            \n",
    "\n",
    "        config = CocoSynthConfig()\n",
    "\n",
    "        class InferenceConfig(CocoSynthConfig):\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "            IMAGE_MIN_DIM = 4096\n",
    "            IMAGE_MAX_DIM = 4096\n",
    "            DETECTION_MIN_CONFIDENCE = 0.5\n",
    "            DETECTION_MAX_INSTANCES = 4000\n",
    "            POST_NMS_ROIS_INFERENCE =  10000\n",
    "\n",
    "        inference_config = InferenceConfig()\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", model_dir=MRCNN_ROOT, config=inference_config)\n",
    "        model.load_weights(MRCNN_MODEL_PATH, by_name=True)\n",
    "        \n",
    "        print('Model loaded successfully.')\n",
    "        leaf_predictions(ORTHO_FOLDER, ortho_file, model, shape_leaf_path,input_image_size)\n",
    "        shape_leaf = gpd.read_file(shape_leaf_path)\n",
    "        LEAF_PROCESSING = True\n",
    "\n",
    "INSTANCE_FORM = 'BOTH'\n",
    "\n",
    "# Process LEAF and CIRCLE instances if LEAF_PROCESSING is enabled\n",
    "if LEAF_PROCESSING:\n",
    "    model = keras.models.load_model(cnn_model_path)\n",
    "    multi_poly, labels = [], []\n",
    "    \n",
    "    for P in tqdm(range(226,len(shape_plot))):\n",
    "        plot_id_temp = plot_list_id[P]\n",
    "        # Crop plot\n",
    "        shape_temp = shape_plot[shape_plot['plot_id'] == plot_id_temp]\n",
    "        try:\n",
    "            S1, S1_transform, S1_bounds = read_raster_window(shape_temp, ortho_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cropping plot: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if S1 is not None:\n",
    "            # Create a dictionary to store parameters\n",
    "                params = {\n",
    "                    'S1': S1,\n",
    "                    'plot_id_temp': plot_id_temp,\n",
    "                    'RESULTS_FOLDER_ROOT': RESULTS_FOLDER_ROOT,\n",
    "                    'INSTANCE_FORM': INSTANCE_FORM,\n",
    "                    'shape_leaf': shape_leaf,\n",
    "                    'shape_temp': shape_temp,\n",
    "                    'ortho_file_path': ortho_file_path,\n",
    "                    'area_path': area_path,\n",
    "                    'rmux_data_t': rmux_data_t,\n",
    "                    'rmuy_data_t': rmuy_data_t,\n",
    "                    'n_ins_test': n_ins_test,\n",
    "                    'MAX_AREA_LEAF': MAX_AREA_LEAF,\n",
    "                    'bands': bands,\n",
    "                    'pipeline': pipeline,\n",
    "                    'model': model,\n",
    "                    'class_output': class_output,\n",
    "                    'min_pix_pred': min_pix_pred,\n",
    "                    'th_erosion': th_erosion,\n",
    "                    'F1': F1,\n",
    "                    'slope_path': slope_path,\n",
    "                    'profile': profile,\n",
    "                    'n_ins': n_ins,\n",
    "                    'DI_THRESHOLD': DI_THRESHOLD,\n",
    "                    'UTMzone': UTMzone\n",
    "                }\n",
    "\n",
    "                # Process condition plot\n",
    "                condition_plot_results = process_condition_plot(params)\n",
    "\n",
    "                # Extract returned values from the dictionary\n",
    "                LEAF_CONDITION = condition_plot_results['LEAF_CONDITION']\n",
    "                leaf_mask_pred = condition_plot_results['mask_pred']\n",
    "                leaf_instance_vector = condition_plot_results['instance_vector']\n",
    "                leaf_cluster_vector = condition_plot_results['cluster_vector']\n",
    "                size_vector = condition_plot_results['size_vector']\n",
    "                slope_vector = condition_plot_results['slope_vector']\n",
    "                T1_leaf = condition_plot_results['T1']\n",
    "                n_ins_sample = condition_plot_results['n_ins_sample']\n",
    "                RESULTS_FOLDER = condition_plot_results['RESULTS_FOLDER']\n",
    "                folder_name_temp = condition_plot_results['folder_name_temp']\n",
    "                final_sel_leaf_id = condition_plot_results['final_sel_leaf_id']\n",
    "                T1_transform = condition_plot_results['T1_transform']\n",
    "                output_leaf_shape_plot = condition_plot_results['output_leaf_shape_plot']\n",
    "                rr_ed_leaf = condition_plot_results['rr_ed']\n",
    "\n",
    "                # Generate and save leaf images\n",
    "                imaging_leaf_updated(T1_leaf,RESULTS_FOLDER,rr_ed_leaf,leaf_cluster_vector,leaf_mask_pred,shape_temp,ortho_file_path)      \n",
    "\n",
    "                # Update the parameter dictionary with additional values\n",
    "                params.update({\n",
    "                    'leaf_mask_pred': leaf_mask_pred,\n",
    "                    'leaf_cluster_vector': leaf_cluster_vector.flatten(),\n",
    "                    'leaf_instance_vector': leaf_instance_vector,\n",
    "                    'size_vector': size_vector,\n",
    "                    'slope_vector': slope_vector,\n",
    "                    'n_ins_sample': n_ins_sample,\n",
    "                    'T1_leaf': T1_leaf,\n",
    "                    'shape_leaf': shape_leaf,\n",
    "                    'RESULTS_FOLDER': RESULTS_FOLDER,\n",
    "                    'folder_name_temp': folder_name_temp,\n",
    "                    'plot_id_temp': plot_id_temp,\n",
    "                    'final_sel_leaf_id': final_sel_leaf_id,\n",
    "                    'output_leaf_shape_plot': output_leaf_shape_plot\n",
    "                })\n",
    "\n",
    "                # Calculate leaf parameters\n",
    "                leaf_param_results = leaf_parameter_cal(params)\n",
    "\n",
    "                # Extract returned values from the dictionary\n",
    "                leaf_parameter = leaf_param_results['leaf_parameter']\n",
    "                DECISION_PLOT_temp = leaf_param_results['DECISION_PLOT_temp']\n",
    "\n",
    "                # Process circles\n",
    "                circle_process_results = circle_processing(params)\n",
    "\n",
    "                # Extract returned values from the dictionary\n",
    "                circle_prediction = circle_process_results['mask_pred_circle']\n",
    "                circle_cluster_vector = circle_process_results['cluster_vector']\n",
    "                circle_instance_vector = circle_process_results['instance_vector']\n",
    "                circle_size_vector = circle_process_results['size_vector']\n",
    "                output_circle_shape_plot = circle_process_results['circle_gdf']\n",
    "                rr_ed_circle = circle_process_results['rr_ed']\n",
    "                T1_circle = circle_process_results['T1']\n",
    "\n",
    "                # Update parameters for circle calculations\n",
    "                params.update({\n",
    "                    'circle_prediction': circle_prediction.flatten(),\n",
    "                    'circle_cluster_vector': circle_cluster_vector.flatten(),\n",
    "                    'circle_instance_vector': circle_instance_vector,\n",
    "                    'circle_size_vector': circle_size_vector,\n",
    "                    'output_circle_shape_plot': output_circle_shape_plot,\n",
    "                    'rr_ed_circle': rr_ed_circle,\n",
    "                    'T1_circle': T1_circle\n",
    "                })\n",
    "\n",
    "                # Calculate circle parameters\n",
    "                circle_param_results = circle_parameter_cal(params)\n",
    "\n",
    "                # Extract returned values from the dictionary\n",
    "                circle_parameter = circle_param_results['circle_parameter']\n",
    "\n",
    "                # Generate and save circle images\n",
    "                imaging_circle_updated(ortho_file_path,shape_temp,RESULTS_FOLDER,rr_ed_circle,circle_cluster_vector, circle_prediction)\n",
    "                # Compile results into DataFrame\n",
    "                df_t = {\n",
    "                    'date_id': date_id,\n",
    "                    'plot_id': plot_id_temp,\n",
    "                    'plot': P,\n",
    "                    **leaf_parameter,  # Merge leaf parameters\n",
    "                    **circle_parameter,  # Merge circle parameters directly\n",
    "                    'DECISION': DECISION_PLOT_temp\n",
    "                }\n",
    "                values = pd.concat([values, pd.DataFrame([df_t])], ignore_index=True)\n",
    "        \n",
    "      \n",
    "\n",
    "# Final processing and saving results\n",
    "values = pd.DataFrame(values)\n",
    "values = values.sort_values(by=['plot']).reset_index(drop=True)\n",
    "\n",
    "# Update spatial data\n",
    "modified_shape_plot = shape_plot.copy()\n",
    "modified_shape_plot['DECISION'] = values['DECISION']\n",
    "\n",
    "# Match design data with values\n",
    "design_miniplot_mod = design_miniplot.sort_values(by=['plot_id'])\n",
    "values['grid_id'] = design_miniplot_mod['grid_id'].values\n",
    "values['block'] = design_miniplot_mod['block'].values\n",
    "values['miniplot_label'] = design_miniplot_mod['fid'].values\n",
    "values['fid'] = design_miniplot_mod['fid'].values\n",
    "\n",
    "# Save parameters to CSV\n",
    "file_name_parameter_series = \"parameter_report.csv\"\n",
    "values.to_csv(os.path.join(RESULTS_FOLDER_ROOT, file_name_parameter_series), index=False)\n",
    "print(f\"Parameters saved to {RESULTS_FOLDER_ROOT / file_name_parameter_series}\")\n",
    "\n",
    "# Save spatial data to GeoPackage\n",
    "modified_shape_plot_gdf = gpd.GeoDataFrame(modified_shape_plot)\n",
    "modified_shape_plot_gdf.to_file(os.path.join(RESULTS_FOLDER_ROOT, \"application_map.gpkg\"), driver=\"GPKG\")\n",
    "print(f\"Spatial data saved to {RESULTS_FOLDER_ROOT / 'application_map.gpkg'}\")\n",
    "\n",
    "# Merging parameters with spatial data\n",
    "modified_shape_plot['leaf_mean_n_cluster'] = values['leaf_mean_n_cluster']\n",
    "# Repeat for other parameters as needed\n",
    "\n",
    "# Save complete spatial data to another GeoPackage\n",
    "modified_shape_plot_gdf_complete = gpd.GeoDataFrame(modified_shape_plot)\n",
    "modified_shape_plot_gdf_complete.to_file(os.path.join(RESULTS_FOLDER_ROOT, \"application_map_complete.gpkg\"), driver=\"GPKG\")\n",
    "print(f\"Complete spatial data saved to {RESULTS_FOLDER_ROOT / 'application_map_complete.gpkg'}\")\n",
    "\n",
    "# Print execution time\n",
    "end_time = pd.Timestamp.now()\n",
    "print(f\"Execution finished at: {end_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hhh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
